# Rate Limiting - Token Bucket Implementation

## Vue d'ensemble

Le systÃ¨me de rate limiting protÃ¨ge l'API contre les abus et les coÃ»ts excessifs, particuliÃ¨rement pour les appels LLM coÃ»teux. Il utilise l'algorithme **Token Bucket** avec support de burst pour Ã©quilibrer protection et expÃ©rience utilisateur.

## Architecture

### Algorithme Token Bucket

Contrairement aux approches classiques (sliding window, fixed window), le token bucket offre :

- **Burst tolerance** : Permet des pics de trafic lÃ©gitimes (ex: retry rapide aprÃ¨s erreur)
- **Distribution lisse** : Les tokens se rechargent progressivement dans le temps
- **PrÃ©cision** : Gestion granulaire des requÃªtes

```
Bucket : [ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™] (5 tokens)
         â†“ 1 requÃªte consomme 1 token
Bucket : [ğŸª™ ğŸª™ ğŸª™ ğŸª™ âšª] (4 tokens restants)
         â†“ Temps Ã©coulÃ© : recharge progressive
Bucket : [ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™] (rechargÃ©)
```

### Fichiers clÃ©s

```
src/
â”œâ”€â”€ constants/rate.ts          # Politiques par route
â”œâ”€â”€ middleware/rate-limit.ts   # ImplÃ©mentation token bucket
app/api/
â”œâ”€â”€ upload/route.ts            # 5 req/min (burst: +2)
â”œâ”€â”€ analyze/route.ts           # 3 req/5min (burst: +1) âš ï¸ CRITIQUE
â”œâ”€â”€ prepare/route.ts           # 5 req/min (burst: +2)
â””â”€â”€ parse/route.ts             # 10 req/min (burst: +2)
```

## Politiques de rate limiting

| Route          | Limite | FenÃªtre | Burst | Raison                      |
| -------------- | ------ | ------- | ----- | --------------------------- |
| `/api/upload`  | 5      | 1 min   | +2    | Upload de fichiers          |
| `/api/analyze` | 3      | 5 min   | +1    | **CoÃ»ts LLM Ã©levÃ©s**        |
| `/api/prepare` | 5      | 1 min   | +2    | PrÃ©paration de texte        |
| `/api/parse`   | 10     | 1 min   | +2    | Parsing PDF (moins coÃ»teux) |

### Pourquoi ces limites ?

- **`/api/analyze`** : La plus stricte (3 req/5min) car chaque appel = coÃ»t LLM significatif
- **Burst tolerance** : +1 ou +2 tokens au-dessus de la limite pour gÃ©rer les retries lÃ©gitimes
- **IP-based** : Une IP partagÃ©e (NAT, VPN) peut affecter plusieurs utilisateurs

## Identification des clients

### DÃ©tection d'IP

PrioritÃ© des headers proxy :

1. `x-forwarded-for` (Vercel, most proxies) â†’ premier IP de la liste
2. `x-real-ip` (Nginx)
3. `cf-connecting-ip` (Cloudflare)
4. Fallback : `127.0.0.1` (dev) ou `0.0.0.0` (prod)

### Normalisation

- **IPv4** : UtilisÃ© tel quel (ex: `192.168.1.100`)
- **IPv6** : Normalisation simple (suppression zÃ©ros leading)

### Stockage

- **ClÃ©** : `{ip}:{route}` (ex: `192.168.1.100:/api/analyze`)
- **Structure** : `Map<string, TokenBucket>` (en mÃ©moire)
- **Nettoyage** : Buckets inactifs >10 min supprimÃ©s tous les 5 min

## Configuration

### Variables d'environnement

Override des politiques par route :

```bash
# Override upload limit (default: 5)
RATE_API_UPLOAD_LIMIT=10

# Override upload window (default: 60000ms = 1 min)
RATE_API_UPLOAD_WINDOW_MS=120000

# Bypass rate limiting (admin)
BYPASS_RATE_LIMIT_FOR_ADMIN=true
```

### Format des variables

Route `/api/upload` â†’ Env prefix `RATE_API_UPLOAD_*`

- Slash (`/`) â†’ Underscore (`_`)
- Prefix `RATE_` automatique
- Suffix `_LIMIT` ou `_WINDOW_MS`

## RÃ©ponses HTTP

### Success (limite non atteinte)

```http
200 OK
X-RateLimit-Limit: 5
X-RateLimit-Remaining: 3
X-RateLimit-Reset: 1704124800
```

### Rate limit exceeded

```http
429 Too Many Requests
X-RateLimit-Limit: 5
X-RateLimit-Remaining: 0
X-RateLimit-Reset: 1704124800

{
  "error": "Trop de requÃªtes. Veuillez rÃ©essayer dans 45 secondes.",
  "code": "RATE_LIMIT_EXCEEDED",
  "resetIn": 45000
}
```

## MÃ©triques et observabilitÃ©

### MÃ©triques disponibles

```typescript
import { getRateLimitMetrics } from "@/src/middleware/rate-limit";

const metrics = getRateLimitMetrics();
// {
//   totalBlocked: 142,
//   blockedByRoute: {
//     "/api/analyze": 89,
//     "/api/upload": 53
//   },
//   activeBuckets: 1247
// }
```

### Logs de dÃ©veloppement

En mode `NODE_ENV=development` :

```
[RateLimit] Blocked: /api/analyze { ip: '192.168.1.100', remaining: 0, resetIn: '45s', limit: 3 }
[RateLimit] Cleaned up 12 expired buckets
```

## Extension Redis/KV

Le systÃ¨me est conÃ§u pour Ãªtre Ã©tendu Ã  Redis/KV pour la production :

### Interface Ã  implÃ©menter

```typescript
interface RateLimitStore {
  get(key: string): Promise<TokenBucket | null>;
  set(key: string, bucket: TokenBucket): Promise<void>;
  delete(key: string): Promise<void>;
}
```

### Avantages Redis

- **ScalabilitÃ©** : PartagÃ© entre instances
- **Persistance** : Survit aux redÃ©marrages
- **TTL natif** : Expiration automatique
- **Atomic operations** : INCR/DECR pour concurrence

### Migration progressive

```typescript
// src/middleware/rate-limit.ts
const store = process.env.REDIS_URL
  ? new RedisRateLimitStore(process.env.REDIS_URL)
  : new MemoryRateLimitStore();
```

## ConsidÃ©rations de sÃ©curitÃ©

### Protection

âœ… **ProtÃ¨ge contre** :

- Spam / abus d'API
- CoÃ»ts LLM incontrÃ´lÃ©s
- DDoS lÃ©ger (IP-based)

âŒ **Ne protÃ¨ge PAS contre** :

- DDoS distribuÃ© (multiples IPs)
- Attaques sophistiquÃ©es (IP rotation)
- Abus intra-quota (utilisateur lÃ©gitime qui abuse)

### Recommandations

1. **Monitoring** : Surveiller `metrics.blockedByRoute` pour dÃ©tecter patterns anormaux
2. **Admin bypass** : Utiliser avec prÃ©caution (`BYPASS_RATE_LIMIT_FOR_ADMIN=true`)
3. **Faux positifs** : IP partagÃ©es (NAT, VPN) â†’ considÃ©rer rate limiting par user ID
4. **Combinaison** : Rate limiting + quota system = protection complÃ¨te

## Debugging

### Tester rate limiting localement

```bash
# 6 requÃªtes rapides (devrait bloquer la 6Ã¨me si limite = 5)
for i in {1..6}; do
  curl -X POST http://localhost:3000/api/upload \
    -H "Content-Type: multipart/form-data" \
    -F "file=@test.pdf"
  echo "\n---"
done
```

### VÃ©rifier les buckets actifs

```typescript
import { getRateLimitStoreSize } from "@/src/middleware/rate-limit";

console.log(`Active buckets: ${getRateLimitStoreSize()}`);
```

### Reset manuel (dev uniquement)

```typescript
import { clearRateLimitStore } from "@/src/middleware/rate-limit";

clearRateLimitStore(); // âš ï¸ Dev only!
```

## FAQ

### Pourquoi token bucket plutÃ´t que sliding window ?

**Token bucket** :

- âœ… Burst tolerance naturelle
- âœ… Distribution lisse des requÃªtes
- âœ… Gestion fine des pics lÃ©gitimes

**Sliding window** :

- âŒ Burst = dÃ©passement de limite
- âŒ Window reset brutal
- âœ… Plus simple Ã  implÃ©menter

### Que se passe-t-il si l'IP est introuvable ?

Le systÃ¨me log un warning et **autorise la requÃªte** :

```
[RateLimit] Cannot identify client, allowing request
```

### Comment gÃ©rer les IP partagÃ©es (NAT) ?

Deux approches :

1. **Augmenter les limites** pour les routes concernÃ©es
2. **Combiner IP + user ID** pour authenticated users
3. **Whitelist** des IP connues (bureaux, VPN corporate)

### Le rate limiting persiste-t-il aprÃ¨s redÃ©marrage ?

**Non** (en mÃ©moire). Pour persistance â†’ migrer vers Redis/KV.

## RÃ©fÃ©rences

- [Token Bucket Algorithm](https://en.wikipedia.org/wiki/Token_bucket)
- [Rate Limiting Patterns](https://cloud.google.com/architecture/rate-limiting-strategies-techniques)
- [X-RateLimit Headers (IETF)](https://datatracker.ietf.org/doc/html/draft-ietf-httpapi-ratelimit-headers)
